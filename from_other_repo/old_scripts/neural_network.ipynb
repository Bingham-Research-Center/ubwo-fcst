{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pull out data from SQL into pandas \n",
    "# pd.read_sql()\n",
    "\n",
    "# Add time \n",
    "# display(df_q)\n",
    "dts = pd.to_datetime(df_q[\"date_time\"])\n",
    "df_q[\"date_time\"] = dts\n",
    "df_q['hour'] = df_q.date_time.dt.hour\n",
    "# df_q = df.assign(hour=df_q.date_time.dt.hour)\n",
    "# display(df_q)\n",
    "\n",
    "df_q['day_of_year'] = df_q.date_time.dt.dayofyear\n",
    "\n",
    "df_q['hour_sin'] = np.sin(2 * np.pi * df_q['hour'] / 24)\n",
    "df_q['hour_cos'] = np.cos(2 * np.pi * df_q['hour'] / 24)\n",
    "df_q['day_of_year_sin'] = np.sin(2 * np.pi * df_q['day_of_year'] / 365.25)\n",
    "df_q['day_of_year_cos'] = np.cos(2 * np.pi * df_q['day_of_year'] / 365.25)\n",
    "\n",
    "df_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "class MaskedRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(MaskedRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x, mask):\n",
    "        method1 = True; method2 = False\n",
    "        if method1:\n",
    "            x = x * mask  # Element-wise multiplication\n",
    "            h_0 = torch.zeros(1, x.size(0), self.hidden_size)\n",
    "            out, _ = self.rnn(x.unsqueeze(1), h_0)  # Adding sequence dimension\n",
    "            out = self.fc(out.squeeze(1))  # Removing sequence dimension\n",
    "            return out\n",
    "        elif method2:     \n",
    "            x = x * mask  # Element-wise multiplication\n",
    "            h_0 = torch.zeros(1, x.size(0), self.hidden_size)\n",
    "            out, _ = self.rnn(x, h_0)\n",
    "            out = self.fc(out[:, -1, :])\n",
    "            return out\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eba0d461abb10aca"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# inputs = [\"elevation\",\"air_temp\",\"dew_point_temperature\",\"pressure\",\"wind_u\",\"wind_v\",\"air_density\",\"hour_sin\",\"hour_cos\",\"day_of_year_sin\",\"day_of_year_cos\"]\n",
    "inputs = [\"elevation\",\"dew_point_temperature\",\"pressure\",\"wind_u\",\"wind_v\",\"air_density\",\"hour_sin\",\"hour_cos\",\"day_of_year_sin\",\"day_of_year_cos\"]\n",
    "target = \"air_temp\"\n",
    "\n",
    "# We want to include station \"IDs\" as one-hot codes\n",
    "# Assuming df is your DataFrame and 'station_id' is the column with station IDs\n",
    "df_one_hot = pd.get_dummies(df_q['stid'], prefix='station')\n",
    "# Concatenate the one-hot encoded columns to original df\n",
    "df_q = pd.concat([df_q, df_one_hot], axis=1)\n",
    "\n",
    "# Now df will have additional columns, each representing a unique station ID\n",
    "display(df_q)\n",
    "\n",
    "# Impute missing values before conversion to PyTorch Tensors\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = imputer.fit_transform(df_q[inputs])\n",
    "Y_imputed = df_q[target].fillna(df_q[target].mean())  # or another imputation strategy\n",
    "\n",
    "# Convert to PyTorch Tensors\n",
    "X = torch.tensor(X_imputed, dtype=torch.float32)\n",
    "Y = torch.tensor(Y_imputed.values, dtype=torch.float32)\n",
    "\n",
    "# Convert DataFrame to PyTorch Tensors\n",
    "# X = torch.tensor(df_q[inputs].values, dtype=torch.float32)\n",
    "# Y = torch.tensor(df_q[target].values, dtype=torch.float32)\n",
    "\n",
    "# Create mask for missing values\n",
    "mask = ~torch.isnan(X)  # Set True where data is NOT missing\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test, mask_train, mask_test = train_test_split(X, Y, mask, test_size=0.1)\n",
    "\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "\n",
    "input_size = len(inputs)\n",
    "hidden_size = 50\n",
    "output_size = 1\n",
    "model = MaskedRNN(input_size, hidden_size, output_size)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "loss_function = torch.nn.MSELoss()\n",
    "\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(X_train, mask_train).squeeze(1)\n",
    "    loss = loss_function(output, Y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item()}')\n",
    "\n",
    "# After forward pass\n",
    "if torch.isnan(output).any():\n",
    "    print('Output has NaN values')\n",
    "\n",
    "# After backward pass\n",
    "if torch.isnan(loss).any():\n",
    "    print('Loss has NaN values')\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    if torch.isnan(param.grad).any():\n",
    "        print(f'Gradient for {name} contains NaNs.')\n",
    "\n",
    "# Check if Y_train contains any NaNs\n",
    "if torch.isnan(Y_train).any():\n",
    "    print('Target variable Y_train contains NaN values')\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3c36d9187c63360a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Let's do a test forecast.\n",
    "\n",
    "# Using the previously scaled test data and mask\n",
    "X_test_scaled = torch.tensor(scaler.transform(X_test), dtype=torch.float32)\n",
    "# Note: No need to create a mask here, as you already have mask_test\n",
    "\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    predicted_output = model(X_test_scaled, mask_test).squeeze(1)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Converting tensors to NumPy arrays for evaluation\n",
    "Y_test_array = Y_test.numpy()\n",
    "predicted_output_array = predicted_output.numpy()\n",
    "\n",
    "# Computing the metrics\n",
    "rmse = np.sqrt(mean_squared_error(Y_test_array, predicted_output_array))\n",
    "mae = mean_absolute_error(Y_test_array, predicted_output_array)\n",
    "\n",
    "print(f'Root Mean Squared Error: {rmse}')\n",
    "print(f'Mean Absolute Error: {mae}')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d5da7215723802cf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Now let's look forecast-by-forecast\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Convert PyTorch tensors to NumPy arrays\n",
    "Y_test_array = Y_test.detach().cpu().numpy()\n",
    "predicted_output_array = predicted_output.detach().cpu().numpy()\n",
    "\n",
    "# Create a Pandas DataFrame\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Actual': Y_test_array,\n",
    "    'Predicted': predicted_output_array,\n",
    "    'Error': Y_test_array - predicted_output_array\n",
    "})\n",
    "\n",
    "# Optionally, compute the absolute error and append to DataFrame\n",
    "comparison_df['Absolute_Error'] = np.abs(comparison_df['Error'])\n",
    "\n",
    "# Display the DataFrame\n",
    "print(comparison_df.head(20))\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6c48f3a9d325851a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Fit a separate StandardScaler for the target\n",
    "target_scaler = StandardScaler()\n",
    "Y_train_reshaped = Y_train.detach().cpu().numpy().reshape(-1, 1)\n",
    "target_scaler.fit(Y_train_reshaped)\n",
    "\n",
    "# Inverse transform the predicted output\n",
    "predicted_output_reshaped = predicted_output.detach().cpu().numpy().reshape(-1, 1)\n",
    "predicted_output_original_scale = target_scaler.inverse_transform(predicted_output_reshaped)\n",
    "\n",
    "# Create a DataFrame for easy comparison\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Actual': Y_test.detach().cpu().numpy().reshape(-1, 1).squeeze(),\n",
    "    # 'Actual': target_scaler.inverse_transform(Y_test.detach().cpu().numpy().reshape(-1, 1)).squeeze(),\n",
    "    'Predicted': predicted_output_original_scale.squeeze(),\n",
    "})\n",
    "\n",
    "# Compute the error terms for each observation\n",
    "comparison_df['Error'] = comparison_df['Actual'] - comparison_df['Predicted']\n",
    "\n",
    "# Optionally, add a column for the absolute error\n",
    "comparison_df['Absolute_Error'] = np.abs(comparison_df['Error'])\n",
    "\n",
    "# Display the DataFrame\n",
    "print(comparison_df.head(20))\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "91da59aae091a598"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "df_q['stid_encoded'] = encoder.fit_transform(df_q['stid'])\n",
    "\n",
    "class MaskedRNNWithEmbedding(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_stations):\n",
    "        super(MaskedRNNWithEmbedding, self).__init__()\n",
    "        \n",
    "        # The \"10\" should be just len of other variables?\n",
    "        self.embedding = nn.Embedding(num_stations, 10)  # 10 is the embedding dimension\n",
    "        self.rnn = nn.RNN(input_size + 10, hidden_size)  # \"+ 10\" to account for the added embedding dimensions\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x, station_ids, mask):\n",
    "        station_embedding = self.embedding(station_ids)\n",
    "        x_combined = torch.cat((x, station_embedding), dim=1)\n",
    "        x = x_combined * mask  # Element-wise multiplication\n",
    "        h_0 = torch.zeros(1, x.size(0), self.hidden_size)\n",
    "        out, _ = self.rnn(x.unsqueeze(1), h_0)  # Adding sequence dimension\n",
    "        out = self.fc(out.squeeze(1))  # Removing sequence dimension\n",
    "        return out\n",
    "\n",
    "station_ids = torch.tensor(df['stid_encoded'].values, dtype=torch.long)\n",
    "\n",
    "\n",
    "output = model(X_train, station_ids_train, mask_train).squeeze(1)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b8ae44f1ba58a023"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
